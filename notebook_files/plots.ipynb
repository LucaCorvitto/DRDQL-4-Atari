{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_names = ['DQN', 'DDQN', 'DRDQN', 'DRQN']\n",
    "plots = ['training_loss', 'cumulative_reward']\n",
    "env_name = 'SpaceInvaders' #'Qbert'\n",
    "updating_steps = 4\n",
    "\n",
    "for plot_type in plots:\n",
    "    for network_name in network_names:\n",
    "\n",
    "        training_values = []\n",
    "        mean_dash = []\n",
    "\n",
    "        # compute mean loss for each epoch (over the 4 actions taken)\n",
    "        with open(f'train_info/{plot_type}_{network_name}.txt', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            \n",
    "            # Loop through lines in groups of 4\n",
    "            for i in range(0, len(lines), updating_steps):\n",
    "                # Get the next 4 lines\n",
    "                epoch_values = lines[i:i+updating_steps]\n",
    "                for j in range(len(epoch_values)):\n",
    "                    epoch_values[j] = float(epoch_values[j].strip())\n",
    "\n",
    "                # compute the mean\n",
    "                mean_epoch_value = np.mean(epoch_values)\n",
    "                training_values.append(mean_epoch_value)\n",
    "\n",
    "        #compute mean value to plot\n",
    "        window = len(training_values) // 100\n",
    "        for i in range(len(training_values) - window + 1):\n",
    "            mean_dash.append(np.mean(training_values[i:i+window]))\n",
    "\n",
    "        # Generate x-axis values for epochs\n",
    "        epochs = range(1, len(training_values) + 1)\n",
    "\n",
    "        # Plotting the training loss\n",
    "        plt.plot(epochs, training_values)\n",
    "        # Plotting mean dash value\n",
    "        plt.plot(mean_dash, linestyle = '--')\n",
    "\n",
    "        # Labels and title\n",
    "        plt.xlabel('Epoch')\n",
    "        if plot_type == 'training_loss':\n",
    "            plt.ylabel('Training Loss')\n",
    "            plt.title(f'{network_name} Training Loss')\n",
    "        else:\n",
    "            plt.ylabel('Cumulative Reward')\n",
    "            plt.title(f'{network_name} Cumulative Reward')\n",
    "\n",
    "        #save the plot\n",
    "        plots_folder = 'plots'\n",
    "        create_dir(plots_folder)\n",
    "        create_dir(env_name)\n",
    "        plt.savefig(f'{plots_folder}/{env_name}/{network_name}_{plot_type}.png')\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
